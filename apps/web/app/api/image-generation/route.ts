import { auth } from '@clerk/nextjs/server';
import { getLanguageModel } from '@repo/ai/providers';
import { ModelEnum } from '@repo/ai/models';
import { generateText } from 'ai';
import { NextRequest, NextResponse } from 'next/server';
import { z } from 'zod';

const imageGenerationRequestSchema = z.object({
    prompt: z.string().min(1),
    image: z.object({
        data: z.string(), // base64 string
        mimeType: z.string(),
    }).optional(),
});

export async function POST(request: NextRequest) {
    try {
        const session = await auth();
        // Note: Not requiring auth for now, but can be enabled later
        // const userId = session?.userId;

        const body = await request.json();
        const validatedData = imageGenerationRequestSchema.safeParse(body);

        if (!validatedData.success) {
            return NextResponse.json(
                { error: 'Invalid request data', details: validatedData.error.format() },
                { status: 400 }
            );
        }

        const { prompt, image } = validatedData.data;

        // Get the Gemini model for image generation
        const model = getLanguageModel(ModelEnum.GEMINI_2_5_FLASH_IMAGE_PREVIEW);

        // Prepare content for the model
        let content: any[] = [
            { 
                type: 'text', 
                text: image 
                    ? `Please modify this image according to the following instruction: ${prompt}` 
                    : `Please generate an image based on this description: ${prompt}`
            }
        ];

        // Add image if provided
        if (image) {
            content.push({
                type: 'image',
                image: image.data,
                mimeType: image.mimeType
            });
        }

        // For now, we'll return a placeholder response since the actual image generation 
        // with Gemini's multimodal capabilities requires proper setup and may not be 
        // directly supported through the current AI SDK implementation
        
        // This is a temporary mock response to demonstrate the UI functionality
        const mockImageResponse = {
            images: [
                {
                    dataUrl: 'data:image/svg+xml;base64,' + btoa(`
                        <svg width="512" height="512" xmlns="http://www.w3.org/2000/svg">
                            <rect width="512" height="512" fill="#f0f9ff"/>
                            <text x="50%" y="40%" text-anchor="middle" font-family="Arial" font-size="24" fill="#0369a1">
                                Image Generation
                            </text>
                            <text x="50%" y="50%" text-anchor="middle" font-family="Arial" font-size="16" fill="#0369a1">
                                Feature Coming Soon
                            </text>
                            <text x="50%" y="65%" text-anchor="middle" font-family="Arial" font-size="12" fill="#64748b">
                                Prompt: ${prompt.slice(0, 50)}${prompt.length > 50 ? '...' : ''}
                            </text>
                        </svg>
                    `),
                    mediaType: 'image/svg+xml'
                }
            ]
        };

        // TODO: Replace with actual Gemini image generation when the API is properly configured
        /*
        const result = await generateText({
            model,
            messages: [
                {
                    role: 'user',
                    content: content,
                },
            ],
        });

        // Process the actual response from Gemini
        if (result.files && result.files.length > 0) {
            const images = result.files.map((file: any) => {
                let dataUrl = '';
                if (file.data instanceof Uint8Array) {
                    const base64 = btoa(Array.from(file.data, byte => String.fromCharCode(byte)).join(''));
                    dataUrl = `data:${file.mediaType};base64,${base64}`;
                } else if (typeof file.data === 'string') {
                    dataUrl = `data:${file.mediaType};base64,${file.data}`;
                }
                
                return {
                    dataUrl,
                    mediaType: file.mediaType || 'image/png'
                };
            });

            return NextResponse.json({ images });
        } else {
            return NextResponse.json(
                { error: 'No images were generated by the model' },
                { status: 400 }
            );
        }
        */

        return NextResponse.json(mockImageResponse);

    } catch (error) {
        console.error('Error generating image:', error);
        return NextResponse.json(
            { error: 'Failed to generate image', details: error instanceof Error ? error.message : 'Unknown error' },
            { status: 500 }
        );
    }
}